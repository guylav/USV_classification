# -*- coding: utf-8 -*-
"""עותק של Statistics_generator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DXyw8jUYLl3sBkPVMl0j12BFIXaPTD1P
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/E:/

import numpy as np
import PIL.Image as Image
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
import tensorflow_hub as hub
from tensorflow.keras.preprocessing import image
import pandas as pd
import os
import xlrd
import math
import scipy
import scipy.io.wavfile as wavfile
from scipy.signal import butter, lfilter, freqz
import librosa
import librosa.display
import cv2

def butter_highpass_filter(cutoff_H, fs, order):
  nyq = 0.5*fs
  normal_cutoff = cutoff_H/nyq
  b, a = butter(order, normal_cutoff, btype='high', analog=False)
  return a, b

class sample:
  def __init__(self, mother, name, sex, age, matgen, pupgen, rec_num, syls, time_between):
    self.mother = mother
    self.name = name
    self.sex = sex
    self.age = age
    self.matgen = matgen
    self.pupgen = pupgen
    self.rec_num = rec_num
    self.syls = syls
    self.time_between = time_between

# Commented out IPython magic to ensure Python compatibility.
model_path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/E:/model_weights.h5'
model = keras.models.load_model(model_path, custom_objects={'KerasLayer':hub.KerasLayer})

fs = 250000
order = 6
cutoff_H = 30*10**3
c, d = butter_highpass_filter(cutoff_H, fs, order)

# %cd /content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/
data_table = xlrd.open_workbook('Total_Data.xlsx').sheet_by_index(0)
age = data_table.col_values(0, 1)
matgen = data_table.col_values(3, 1)
pupgen = data_table.col_values(5, 1)
mother = data_table.col_values(2, 1)
name = data_table.col_values(4, 1)
sex = data_table.col_values(16, 1)
#syllable = data_table.col_values(14, 1)
rec_num = data_table.col_values(6, 1)
start = data_table.col_values(7, 1)
finish = data_table.col_values(9, 1)

samples = []
sr = 250000
max_time = 0.25
pred = []
timeB = []
time_diff = []
start_arr = np.array(start) #converting to array
finish_arr = np.array(finish)
time_diff = np.subtract(finish_arr, start_arr) #calculating each syllable length
for i in range(len(mother)):
  path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.wav'.format(mother[i], name[i], rec_num[i]) #find path of each recording
  if not os.path.exists('{}'.format(path)):
    path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.WAV'.format(mother[i], name[i], rec_num[i])
    if not os.path.exists('{}'.format(path)):
      continue
  if i>0 and (rec_num[i] != rec_num[i-1] or name[i] != name[i-1]):
    recording = sample(mother[i-1], name[i-1], sex[i-1], age[i-1], matgen[i-1], pupgen[i-1], rec_num[i-1], pred, timeB)
    samples.append(recording)
    pred = []
    timeB = []
  if time_diff[i] < max_time:
    rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs
    temp = (max_time - time_diff[i])/2
    silence = np.zeros(round((temp)*rate))
    trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel
    syl = np.append(silence, trimmed) #normalizing length to max syllable
    syl = np.append(syl, silence)
  else:
    rec, rate = librosa.load(path, sr)
    syl = rec[round((start[i])*rate):round((finish[i])*rate)]
  #pre processing
  syl = lfilter(d, c, syl) #hpf
  #STFT creation
  D = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram
  D = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood
  D = D - 0.02*np.mean(D)
  D = np.repeat(D[:, :, np.newaxis], 3, -1)
  D = D.astype('float32')
  D = D/255
  D = image.img_to_array(D)
  D = np.expand_dims(D, axis=0)
  predict = model.predict(D)
  pred.append(predict)
  if len(pred) > 1:
    timeB.append(start[i] - finish[i-1])

print(samples[201].syls)

samples = np.array(samples)
np.save('model_prediction_recordings' ,samples)

'''
i = 731
pred = []
timeB = 1
sr = 250000 
time_diff = []
start_arr = np.array(start) #converting to array
finish_arr = np.array(finish)
time_diff = np.subtract(finish_arr, start_arr)
max_time = 0.25
path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.wav'.format(mother[i], name[i], rec_num[i])
if time_diff[i] < max_time:
  rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs
  temp = (max_time - time_diff[i])/2
  silence = np.zeros(round((temp)*rate))
  trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel
  syl = np.append(silence, trimmed) #normalizing length to max syllable
  syl = np.append(syl, silence)
else:
  rec, rate = librosa.load(path, sr)
  syl = rec[round((start[i])*rate):round((finish[i])*rate)]
#pre processing
syl = lfilter(d, c, syl) #hpf

D = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram
D = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood
D = D - 0.02*np.mean(D)
fig, ax = plt.subplots(nrows=1, ncols=1)
ax.pcolormesh(20*np.log10(D))
D = np.repeat(D[:, :, np.newaxis], 3, -1)
D = D.astype('float32')
D = D/255
D = image.img_to_array(D)
D = np.expand_dims(D, axis=0)
predict = model.predict(D)
pred.append(predict)
pred.append(predict)
sample1 = sample(mother[i], name[i], sex[i], age[i], matgen[i], pupgen[i], rec_num[i], pred, timeB)
#pred = np.where(pred == np.max(pred))
print(sample1.syls)
'''